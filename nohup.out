/home/lq/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 16, 112, 112, 3)   0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 16, 112, 112, 64)  5248      
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 8, 56, 112, 64)    0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 8, 56, 112, 128)   221312    
_________________________________________________________________
max_pooling3d_2 (MaxPooling3 (None, 4, 28, 56, 128)    0         
_________________________________________________________________
conv3d_3 (Conv3D)            (None, 4, 28, 56, 256)    884992    
_________________________________________________________________
max_pooling3d_3 (MaxPooling3 (None, 2, 14, 28, 256)    0         
_________________________________________________________________
conv3d_4 (Conv3D)            (None, 2, 14, 28, 256)    1769728   
_________________________________________________________________
max_pooling3d_4 (MaxPooling3 (None, 1, 7, 14, 256)     0         
_________________________________________________________________
conv3d_5 (Conv3D)            (None, 1, 7, 14, 256)     1769728   
_________________________________________________________________
max_pooling3d_5 (MaxPooling3 (None, 1, 4, 7, 256)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 7168)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              14682112  
_________________________________________________________________
dropout_1 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dropout_2 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 21)                43029     
_________________________________________________________________
activation_1 (Activation)    (None, 21)                0         
=================================================================
Total params: 23,572,501
Trainable params: 23,572,501
Non-trainable params: 0
_________________________________________________________________
Traceback (most recent call last):
  File "train.py", line 228, in <module>
    main()
  File "train.py", line 184, in main
    model.load_weights('data/conv3d_deepnetA_sport1m_iter_1900000_TF.model', by_name=True)
  File "/home/lq/anaconda3/lib/python3.6/site-packages/keras/engine/network.py", line 1171, in load_weights
    with h5py.File(filepath, mode='r') as f:
  File "/home/lq/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py", line 269, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/home/lq/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py", line 99, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 78, in h5py.h5f.open
OSError: Unable to open file (file signature not found)
2018-08-20 05:57:16.734076: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-08-20 05:57:16.817240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-08-20 05:57:16.817748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX 950 major: 5 minor: 2 memoryClockRate(GHz): 1.405
pciBusID: 0000:27:00.0
totalMemory: 1.95GiB freeMemory: 1.56GiB
2018-08-20 05:57:16.817769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2018-08-20 05:57:17.014222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-08-20 05:57:17.014270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2018-08-20 05:57:17.014278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2018-08-20 05:57:17.014404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1315 MB memory) -> physical GPU (device: 0, name: GeForce GTX 950, pci bus id: 0000:27:00.0, compute capability: 5.2)
2018-08-20 05:57:21.334135: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-08-20 05:57:21.382598: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-08-20 05:57:21.509645: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 16, 112, 112, 3)   0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 16, 112, 112, 64)  5248      
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 8, 56, 112, 64)    0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 8, 56, 112, 128)   221312    
_________________________________________________________________
max_pooling3d_2 (MaxPooling3 (None, 4, 28, 56, 128)    0         
_________________________________________________________________
conv3d_3 (Conv3D)            (None, 4, 28, 56, 256)    884992    
_________________________________________________________________
max_pooling3d_3 (MaxPooling3 (None, 2, 14, 28, 256)    0         
_________________________________________________________________
conv3d_4 (Conv3D)            (None, 2, 14, 28, 256)    1769728   
_________________________________________________________________
max_pooling3d_4 (MaxPooling3 (None, 1, 7, 14, 256)     0         
_________________________________________________________________
conv3d_5 (Conv3D)            (None, 1, 7, 14, 256)     1769728   
_________________________________________________________________
max_pooling3d_5 (MaxPooling3 (None, 1, 4, 7, 256)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 7168)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              14682112  
_________________________________________________________________
dropout_1 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dropout_2 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 21)                43029     
_________________________________________________________________
activation_1 (Activation)    (None, 21)                0         
=================================================================
Total params: 23,572,501
Trainable params: 23,572,501
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
 - 10s - loss: 32.2800 - acc: 0.2500 - val_loss: 30.6448 - val_acc: 0.4000
Epoch 2/10
 - 5s - loss: 30.0891 - acc: 0.2500 - val_loss: 28.6573 - val_acc: 0.4000
Epoch 3/10
 - 5s - loss: 28.0499 - acc: 0.3000 - val_loss: 26.9272 - val_acc: 0.4000
Epoch 4/10
 - 5s - loss: 25.9655 - acc: 0.4000 - val_loss: 25.0758 - val_acc: 0.3000
Epoch 5/10
 - 5s - loss: 25.0824 - acc: 0.3500 - val_loss: 25.0320 - val_acc: 0.2000
Epoch 6/10
 - 5s - loss: 24.8327 - acc: 0.3500 - val_loss: 24.2343 - val_acc: 0.5000
Epoch 7/10
 - 5s - loss: 24.8271 - acc: 0.1500 - val_loss: 24.3869 - val_acc: 0.3500
Epoch 8/10
 - 5s - loss: 24.3411 - acc: 0.4000 - val_loss: 24.1071 - val_acc: 0.4500
Epoch 9/10
 - 5s - loss: 24.3547 - acc: 0.4000 - val_loss: 24.1359 - val_acc: 0.4500
Epoch 10/10
 - 5s - loss: 24.4669 - acc: 0.3000 - val_loss: 24.1480 - val_acc: 0.4500
/home/lq/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/home/lq/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2287: RuntimeWarning: invalid value encountered in sqrt
  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))
2018-08-20 06:09:02.072975: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-08-20 06:09:02.159111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-08-20 06:09:02.159631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX 950 major: 5 minor: 2 memoryClockRate(GHz): 1.405
pciBusID: 0000:27:00.0
totalMemory: 1.95GiB freeMemory: 1.56GiB
2018-08-20 06:09:02.159652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2018-08-20 06:09:02.349991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-08-20 06:09:02.350036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2018-08-20 06:09:02.350043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2018-08-20 06:09:02.350165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1313 MB memory) -> physical GPU (device: 0, name: GeForce GTX 950, pci bus id: 0000:27:00.0, compute capability: 5.2)
2018-08-20 06:09:06.595505: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-08-20 06:09:06.639434: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-08-20 06:09:06.753252: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 16, 112, 112, 3)   0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 16, 112, 112, 64)  5248      
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 8, 56, 112, 64)    0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 8, 56, 112, 128)   221312    
_________________________________________________________________
max_pooling3d_2 (MaxPooling3 (None, 4, 28, 56, 128)    0         
_________________________________________________________________
conv3d_3 (Conv3D)            (None, 4, 28, 56, 256)    884992    
_________________________________________________________________
max_pooling3d_3 (MaxPooling3 (None, 2, 14, 28, 256)    0         
_________________________________________________________________
conv3d_4 (Conv3D)            (None, 2, 14, 28, 256)    1769728   
_________________________________________________________________
max_pooling3d_4 (MaxPooling3 (None, 1, 7, 14, 256)     0         
_________________________________________________________________
conv3d_5 (Conv3D)            (None, 1, 7, 14, 256)     1769728   
_________________________________________________________________
max_pooling3d_5 (MaxPooling3 (None, 1, 4, 7, 256)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 7168)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              14682112  
_________________________________________________________________
dropout_1 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dropout_2 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 21)                43029     
_________________________________________________________________
activation_1 (Activation)    (None, 21)                0         
=================================================================
Total params: 23,572,501
Trainable params: 23,572,501
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
 - 10s - loss: 32.2822 - acc: 0.1000 - val_loss: 30.7024 - val_acc: 0.5000
Epoch 2/10
 - 5s - loss: 29.7810 - acc: 0.3500 - val_loss: 28.1725 - val_acc: 0.4500
Epoch 3/10
 - 5s - loss: 27.4925 - acc: 0.4000 - val_loss: 26.6192 - val_acc: 0.3500
Epoch 4/10
 - 5s - loss: 25.8660 - acc: 0.3500 - val_loss: 24.7609 - val_acc: 0.4000
Epoch 5/10
 - 5s - loss: 24.6450 - acc: 0.3500 - val_loss: 24.5524 - val_acc: 0.3500
Epoch 6/10
 - 5s - loss: 24.7212 - acc: 0.4000 - val_loss: 24.3266 - val_acc: 0.4000
Epoch 7/10
 - 5s - loss: 24.4946 - acc: 0.4000 - val_loss: 24.0198 - val_acc: 0.3000
Epoch 8/10
 - 5s - loss: 23.9260 - acc: 0.4500 - val_loss: 23.9872 - val_acc: 0.3500
Epoch 9/10
 - 5s - loss: 24.2095 - acc: 0.4500 - val_loss: 23.8801 - val_acc: 0.3500
Epoch 10/10
 - 5s - loss: 24.3531 - acc: 0.3500 - val_loss: 24.2671 - val_acc: 0.3500
/home/lq/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/home/lq/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2287: RuntimeWarning: invalid value encountered in sqrt
  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))
